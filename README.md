# 1.Importing library pandas selenium time json,etc.
# 2.write opyions for different mode headless,size.
# 3.function for check xpath exist while scraping 
# 4.initialization of driver and service for chrome.
# 5 read excel file using pd read excel of amazon scraping excel. 
# 6.initialization of data dataframe with the required columns. 
# 7. write code for the extraction of title,details,image url,and price and storing in dataframe and also time execution of every 1 to 100 .
# 8.cleaning od data scraped from website.
# 9.Making of data into json and making SOLUTION.JSON file which is uploaded in git file.
# 10.connection of postgresql of my database. 
# 11.creating of table in sql with datatype.
# 12.writing query for Insert of data into the database.
# 13.writing cursor execution code.
# 14.commit of data into the database.
# 15.Closing of connection with database.
# 16.ingestion of data into ElasticSearch with index amazdata

